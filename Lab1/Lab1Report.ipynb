{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Lab 1: Optical flow</h1></center>\n",
    "<center>Darius Fang Cmput 487 2023W</center>\n",
    "<center>Python 3.8.3</center>\n",
    "<br>\n",
    "<font color=\"#FF0000\">\n",
    "<!-- Demo: In your lab session during the week following the due date. -->\n",
    "</font>\n",
    "<h2>Lab #1.1</h2>\n",
    "<b><font size=\"+1\">Exercise 1 (3):</font></b> <font size=\"+1\">Image differences</font>\n",
    "<p><font size=\"+1\">a (1). Capture images</font>\n",
    "This is the initial part of the report. It is to capture frames and save frames into a folder. The default frame size is 640x480. \n",
    "The example I have below saves the files in 'captureImage', consisting of panning my camera across my plushie. The video only pans left right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#rgb to bgr\n",
    "import matplotlib.pyplot as plt\n",
    "# the line below is used for in the lab\n",
    "# cam = cv2.VideoCapture(0, cv2.CAP_FIREWIRE)\n",
    "# the line below is to capture a normal webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"test\")\n",
    "# path file to be saved\n",
    "path = \"captureImage/\"\n",
    "img_counter = 0\n",
    "while True:\n",
    "    # read frame\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"failed to grab frame\")\n",
    "        break\n",
    "    cv2.imshow(\"test\", frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "    # ASCII:ESC pressed, exit\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "    # ASCII:SPACE pressed, capture frame\n",
    "        img_name = path + \"opencv_frame_{}.png\".format(img_counter)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        # print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "# only prints how many frames were saved\n",
    "print(\"{} written!\".format(img_name))\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "</p><p><font size=\"+1\">b (2). Image differences</font>\n",
    "\n",
    "The \"delta image\" is a crucial aspect of the optic flow function. It is determined by calculating the difference between two images. \n",
    "    $$ \\frac {\\delta Im}{\\delta t} = Im(t+1) - Im(t)$$\n",
    "    It is important to convert the numpy arrays into float data type to avoid any loss of data due to negative numbers and overflow issues. A threshold is set to eliminate image noises and possible light or background noise between the two frames. In the code, a threshold of 10 is used, and any absolute difference found to be less than 10 is set to 0. Note that negative values in the delta image correspond to the opposite direction of the optic flow vector.\n",
    "\n",
    "The example provided only demonstrates the calculation for the first 9 iterations.\n",
    "<br>\n",
    "<br>\n",
    "Input of 2 images\n",
    "<br>\n",
    "<img src=\"captureImage/opencv_frame_8.png\"  width=\"500\"> <img src=\"captureImage/opencv_frame_9.png\"  width=\"500\">\n",
    "\n",
    "<br>\n",
    "Output of the difference (note that this is from opencv imshow, and shows only uint8 type)\n",
    "<br>\n",
    "<img src=\"replaceImage/opencv_difference_9.png\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "path = \"captureImage/\"\n",
    "path1 = \"replaceImage/\"\n",
    "ImageShape = [480,640]\n",
    "imageWidth = ImageShape[1]\n",
    "imageHeight = ImageShape[0]\n",
    "size = (imageWidth, imageHeight)\n",
    "for i in range(10):\n",
    "    #read 2 images\n",
    "    img_nameNew = path + \"opencv_frame_{}.png\".format(i+1)\n",
    "    img_nameOld = path + \"opencv_frame_{}.png\".format(i)\n",
    "    Inew = cv2. imread(img_nameNew,0)\n",
    "    Iold = cv2. imread(img_nameOld,0) \n",
    "    cv2.imshow(\"test1\", Inew)\n",
    "    cv2.imshow(\"test2\", Iold)\n",
    "    #convert to float\n",
    "    Inew = Inew.astype(np.float)\n",
    "    Iold = Iold.astype(np.float)\n",
    "    # take  difference\n",
    "    dIm = np.array(Inew) - np.array(Iold)\n",
    "  \n",
    "\n",
    "    while True:\n",
    "        #Threshold\n",
    "        dIm[np.absolute(dIm)<10] = 0\n",
    "        cv2.imshow(\"test\", dIm.astype(np.float))\n",
    "        k = cv2.waitKey(1)\n",
    "        if k%256 == 27:\n",
    "            break\n",
    "    cv2.imwrite(path1 + \"opencv_difference_{}.png\".format(i), dIm)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<b><font size=\"+1\">Exercise 2 (7):</font></b> <font size=\"+1\">Optical flow</font> \n",
    "\n",
    "In the next step, the computation of the optic flow will be based on user input. For each identified blob in the image, the difference between the two images and the gradient is calculated to determine the vector flow. The vectors are then displayed as an overlay on the image using a quiver plot. It is important to note that changing the block size can affect the calculated optic flow vectors. Sampling a small section will only show movement for small pixel changes, while larger block sizes may result in misleading optic flow errors due to certain conditions. For example, when two objects are moving in different directions (which has not been tested in this case). It is also important to note that 2D optic flow does not solve the aperture problem, which results in an ambiguous determination of the optic flow.\n",
    "\n",
    "2D optic Flow formula:\n",
    "\n",
    "$$ u = M\\backslash  dIm, \\\\ M = \\begin{bmatrix} . & . \\\\ \n",
    "                                                . & . \\\\ \n",
    "                                                \\frac {\\delta Im}{\\delta t} & \\frac {\\delta Im}{\\delta t} \\\\\n",
    "                                                . & . \\\\ \n",
    "                                                . & . \\\\ \\end{bmatrix}, \n",
    "                            dIm = \\begin{bmatrix} . \\\\ \n",
    "                                                .  \\\\ \n",
    "                                                -\\frac {\\delta Im}{\\delta t} \\\\\n",
    "                                                .  \\\\ \n",
    "                                                .  \\\\ \\end{bmatrix},\n",
    "                            u = \\begin{bmatrix} \\delta x \\\\\n",
    "                                                 \\delta y\n",
    "                                               \\end{bmatrix},$$\n",
    "To solve $u$ we have to use the least squares method provided by numpy \n",
    "\n",
    "Update January 31st: There was an error in the orientation of the u and v values, as they were switched. This was due to MATLAB outputting in the format col, row, while numpy outputs in row, col. All of the code for lab 1.2 has been updated to correct this mistake. As a reference, the old tracking code can be found in the previous version and is labeled as \"output_previous (u,v) are flipped\".\n",
    "\n",
    "An example with 64 block size:\n",
    "\n",
    "<img src=\"report Images/outputOptic64_1.jpg\"  width=\"500\"> <img src=\"report Images/outputOptic64_2.jpg\"  width=\"500\">\n",
    "\n",
    "\n",
    "The user inputs the block size by entering a single integer. To input a block size of 2x2, the user should enter '2'.\n",
    "\n",
    "The output will be under 'outputOptic\\<BlockSize>.mp4'\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-29198896480f>:57: RuntimeWarning: invalid value encountered in true_divide\n",
      "  u, v = -arr / np.linalg.norm(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "blockSize = int(input(\"Specify block size: \"))\n",
    "path = \"captureImage/\"\n",
    "ImageShape = [480,640]\n",
    "imageWidth = ImageShape[1]\n",
    "imageHeight = ImageShape[0]\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "result = cv2.VideoWriter('outputOptic' + str(blockSize) + '.mp4', fourcc, 20, (imageWidth, imageHeight))\n",
    "# result.release()\n",
    "for index in range(115):\n",
    "    img_nameNew = path + \"opencv_frame_{}.png\".format(index+1)\n",
    "    img_nameOld = path + \"opencv_frame_{}.png\".format(index)\n",
    "    Inew = cv2. imread(img_nameNew,0)\n",
    "    Iold = cv2. imread(img_nameOld,0) \n",
    "    size = (imageWidth, imageHeight)\n",
    "\n",
    "    Inew = Inew.astype(np.float)\n",
    "    Iold = Iold.astype(np.float)\n",
    "    # difference image  \n",
    "\n",
    "    dIm = np.array(Inew) - np.array(Iold)\n",
    "    dIm = dIm.astype(np.float)\n",
    "    dIm[np.absolute(dIm)<10 ] = 0\n",
    "    ###\n",
    "    ### UPDATE Jan 31\n",
    "    ### dVM and dUm were swaped since np gradient does [rows, col] while in MATLAB it does [col, row]\n",
    "    ###\n",
    "    [dVm, dUm] = np.gradient(Iold)\n",
    "    #row, column -> y, x\n",
    "    X = range(1+int(blockSize/2),imageWidth,blockSize)\n",
    "    Y = range(1+int(blockSize/2),imageHeight,blockSize)\n",
    "    U = np.ones((len(Y),len(X)))\n",
    "    V = np.ones((len(Y),len(X)))\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(Y)):\n",
    "            # get frame\n",
    "            k = j*blockSize\n",
    "            l = i*blockSize\n",
    "            #get blob\n",
    "            dI = dIm[k:k+blockSize, l:l+blockSize]\n",
    "            dU = dUm[k:k+blockSize, l:l+blockSize]\n",
    "            dV = dVm[k:k+blockSize, l:l+blockSize]\n",
    "            # vector, flatten matrix\n",
    "            dIv = dI.flatten()\n",
    "            dUv = dU.flatten()\n",
    "            dVv = dV.flatten()\n",
    "            dIv = np.array([dIv])\n",
    "            #least squares\n",
    "            M = np.array([dUv, dVv])\n",
    "            dIv = dIv.T\n",
    "            M = M.T\n",
    "            arr = np.linalg.lstsq(M,dIv, rcond=None)[0]\n",
    "            # normalise\n",
    "            u, v = -arr / np.linalg.norm(arr)\n",
    "            #x motion\n",
    "            U[j,i] = u\n",
    "            #y motion\n",
    "            V[j,i] = v\n",
    "\n",
    "    [X,Y] = np.meshgrid(X,Y)\n",
    "    Iold = cv2.imread(path + \"opencv_frame_{}.png\".format(index))\n",
    "    Iold = cv2.cvtColor(Iold, cv2.COLOR_BGR2RGB)\n",
    "    # matplotlib configerations to remove border\n",
    "    fig = plt.figure(frameon = False)\n",
    "    fig.set_size_inches(16, 12)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.], )\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    plt.quiver(X,Y,U,V, minlength=4)\n",
    "    ax.imshow(Iold)\n",
    "    fig.canvas.draw()\n",
    "    # matplotlib fig to numpy\n",
    "    image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    image_from_plot = image_from_plot.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    image_from_plot = cv2.cvtColor(image_from_plot, cv2.COLOR_BGR2RGB)\n",
    "    image_from_plot = cv2.resize(image_from_plot, (640,480), interpolation = cv2.INTER_AREA)\n",
    "    # write\n",
    "    result.write(image_from_plot)\n",
    "    plt.clf()\n",
    "    plt.close(\"all\")\n",
    "print(\"finished\")\n",
    "result.release()\n",
    "cv2.destroyAllWindows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h2>Lab 1.2: 2D Video tracking</h2>\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<b><font size=\"+1\">Exercise 1 (5):</font></b>\n",
    "<font size=\"+1\">Translational x-y tracking </font>\n",
    "\n",
    "By leveraging our understanding of optic flow, we will use it to track the movement of a single blob specified by the user. The user will provide an initial position $p$ by drawing it on the screen, along with the frame width and height. For each subsequent optic flow calculation, the position $p$ will be updated based on the calculated vector flow.\n",
    "\n",
    "\n",
    "It is important to note that while this 2D implementation can effectively track an object moving left-right or up-down, it can be challenging to track an object that rotates or undergoes an affine transformation. Scaling the object is not possible using a single vector flow, as scaling is similar to a zoom in/out vector field. Image warping is required to handle affine transformations, and updating the width and height of the image.\n",
    "\n",
    "\n",
    "To maintain precision, the global position p is saved as a float, as the change in the optic flow can sometimes result in fractional numbers. However, for display purposes, the pixels are rounded to an integer. This implementation does not incorporate any image warping, and instead uses registration-based tracking, which is precise but can fail if the object is lost.\n",
    "\n",
    "$$ p = p+u$$\n",
    "\n",
    "An example:\n",
    "\n",
    "<img src=\"report Images/outputTrack2_2.jpg\"  width=\"500\"> <img src=\"report Images/outputTrack2_1.jpg\"  width=\"500\">\n",
    "\n",
    "\n",
    "The user can define the target object by creating a rectangular region of interest on the video frame using a mouse drag. Upon pressing 'esc', the processing of the video will commence. The output will be under 'outputTrack2.mp4'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "blockSize = 16\n",
    "path = \"captureImage/\"\n",
    "ImageShape = [480,640]\n",
    "imageWidth = ImageShape[1]\n",
    "imageHeight = ImageShape[0]\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "result = cv2.VideoWriter('outputTrack2.mp4', fourcc, 20, (imageWidth, imageHeight))\n",
    "# result.release()\n",
    "drawing = False\n",
    "ix,iy = -1,-1\n",
    "width, height = 0,0\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "   global ix, iy, drawing,  width, height\n",
    "   if event == cv2.EVENT_LBUTTONDOWN:\n",
    "      drawing = True\n",
    "      ix = x\n",
    "      iy = y\n",
    "   elif event == cv2.EVENT_LBUTTONUP:\n",
    "      drawing = False\n",
    "      width = x- ix\n",
    "      height = y- iy\n",
    "      print(width, height)\n",
    "      cv2.rectangle(Input, (ix, iy),(ix + width, iy + height),(0, 255, 255),4)\n",
    "\n",
    "img_nameOld = path + \"opencv_frame_{}.png\".format(15)\n",
    "Input = cv2. imread(img_nameOld) \n",
    "cv2.namedWindow(\"test\")\n",
    "cv2.setMouseCallback(\"test\", draw_rectangle)\n",
    "\n",
    "\n",
    "while True:\n",
    "    # dIm[dIm>=80] = 255\n",
    "    cv2.imshow(\"test\", Input)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows\n",
    "for index in range(15,115):\n",
    "    img_nameNew = path + \"opencv_frame_{}.png\".format(index+1)\n",
    "    img_nameOld = path + \"opencv_frame_{}.png\".format(index)\n",
    "    Inew = cv2. imread(img_nameNew,0)\n",
    "    Iold = cv2. imread(img_nameOld,0) \n",
    "    size = (imageWidth, imageHeight)\n",
    "\n",
    "    Inew = Inew.astype(np.float)\n",
    "    Iold = Iold.astype(np.float)\n",
    "    # difference image  \n",
    "    dIm = np.array(Inew) - np.array(Iold)\n",
    "    dIm[np.absolute(dIm)<10 ] = 0\n",
    "    Iold = Iold.astype(np.float)\n",
    "\n",
    "    [dVm, dUm] = np.gradient(Iold)\n",
    "    #row, column -> y, x\n",
    "    intX = int(ix)\n",
    "    intY = int(iy)\n",
    "    dI = dIm[intY:intY+height, intX:intX+width]\n",
    "    dU = dUm[intY:intY+height, intX:intX+width]\n",
    "    dV = dVm[intY:intY+height, intX:intX+width]\n",
    "    # vector, flatten matrix\n",
    "    dIv = dI.flatten()\n",
    "    dUv = dU.flatten()\n",
    "    dVv = dV.flatten()\n",
    "    dIv = np.array([dIv])\n",
    "    #least squares\n",
    "    M = np.array([dUv, dVv])\n",
    "    dIv = dIv.T\n",
    "    M = M.T\n",
    "    # print(np.linalg.lstsq(M,dIv, rcond=None))\n",
    "    arr = np.linalg.lstsq(M,dIv, rcond=None)[0]\n",
    "    u, v = -arr \n",
    "\n",
    "    ix = ix +  u\n",
    "    #y motion\n",
    "    iy = iy +  v\n",
    "    #print(u,v)\n",
    "    Iold = cv2.imread(path + \"opencv_frame_{}.png\".format(index+1))\n",
    "    cv2.rectangle(Iold, (intX, intY),(intX + width, intY + height),(0, 255, 255),4)\n",
    "    # write\n",
    "    result.write(Iold)\n",
    "print(\"finished\")\n",
    "result.release()\n",
    "cv2.destroyAllWindows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size=\"+1\">Exercise 2:</font></b> <font size=\"+1\">Pyramidal tracking</font>\n",
    "\n",
    "Pyramidal tracking provides a more accurate tracking solution compared to the previous implementation. By creating a pyramid of the image through down-sampling and Gaussian filtering, the change in vectors are then propagated, with the highest level having the greatest influence. The user inputs the number of levels and the resizing factor for the pyramid. For example, with 2 levels and a resize of 2, the influence of the top level would be the vector multiplied by $2^2$. This results in a smoother and more precise tracking solution.\n",
    "\n",
    "Update on Jan 31: guassian filter only works with odd integers like 1x1, 3x3 etc. So I also added Pydown to do 1/2 sampling. If any other value is specified it will also do 1/2 sampling. The output of the video is similar to x-y translation, only the translations look smoother due to pyramid giving a better percision than only have 1 level.\n",
    "\n",
    "Example:\n",
    "\n",
    "<img src=\"report Images/outputTrack3_2.jpg\"  width=\"500\"> <img src=\"report Images/outputTrack3_1.jpg\"  width=\"500\">\n",
    "\n",
    "\n",
    "The user can specify the number of levels and resize factor for the pyramidal tracking system. They can interact with the program by drawing a rectangular region on the frame using their mouse. To initiate the processing of the video, the user simply presses the 'esc' key.\n",
    "\n",
    "The output will be under 'outputTrack3.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "blockSize = 16\n",
    "path = \"captureImage/\"\n",
    "ImageShape = [480,640]\n",
    "imageWidth = ImageShape[1]\n",
    "imageHeight = ImageShape[0]\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "result = cv2.VideoWriter('outputTrack3.mp4', fourcc, 20, (imageWidth, imageHeight))\n",
    "# result.release()\n",
    "drawing = False\n",
    "ix,iy = -1,-1\n",
    "width, height = 0,0\n",
    "level = int(input(\"input level:\"))\n",
    "resizeFactor = int(input(\"input resizing factor: \"))\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "   global ix, iy, drawing,  width, height\n",
    "   if event == cv2.EVENT_LBUTTONDOWN:\n",
    "      drawing = True\n",
    "      ix = x\n",
    "      iy = y\n",
    "   elif event == cv2.EVENT_LBUTTONUP:\n",
    "      drawing = False\n",
    "      width = x- ix\n",
    "      height = y- iy\n",
    "      print(ix, iy, width, height)\n",
    "      cv2.rectangle(Input, (ix, iy),(ix + width, iy + height),(0, 255, 255),4)\n",
    "      cv2.destroyAllWindows\n",
    "\n",
    "img_nameOld = path + \"opencv_frame_{}.png\".format(15)\n",
    "Input = cv2. imread(img_nameOld) \n",
    "cv2.namedWindow(\"test\")\n",
    "cv2.setMouseCallback(\"test\", draw_rectangle)\n",
    "\n",
    "# draw rectangle from user, then press esc\n",
    "while True:\n",
    "    cv2.imshow(\"test\", Input)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows\n",
    "for index in range(15,115):\n",
    "    img_nameNew = path + \"opencv_frame_{}.png\".format(index+1)\n",
    "    img_nameOld = path + \"opencv_frame_{}.png\".format(index)\n",
    "    Inew = cv2. imread(img_nameNew,0)\n",
    "    Iold = cv2. imread(img_nameOld,0)\n",
    "    size = (imageWidth, imageHeight)\n",
    "    #pyramid\n",
    "    G = Inew.copy()\n",
    "    gpA = [G]\n",
    "    kernel_size = (resizeFactor, resizeFactor)\n",
    "    for i in range(level):\n",
    "        # Get the new dimensions of the image\n",
    "        rows, cols = G.shape[:2]\n",
    "        new_rows, new_cols = int(rows/resizeFactor), int(cols/resizeFactor)\n",
    "        ###\n",
    "        ### Update Jan 31\n",
    "        ### Pydown was added to do resize factor of 2. 4, 16, etc were not implemented though. any odd resize factor will be assumed to work\n",
    "        ###\n",
    "        # Downsample the image\n",
    "        if (resizeFactor%2 == 1):\n",
    "            G = cv2.GaussianBlur(G, kernel_size, 0)\n",
    "            G = cv2.resize(G, (new_cols, new_rows), cv2.INTER_AREA)\n",
    "        else:\n",
    "            G = cv2.pyrDown(G)\n",
    "        gpA.append(G)\n",
    "    F = Iold.copy()\n",
    "    gpB = [F]\n",
    "    for i in range(level):\n",
    "        rows, cols = F.shape[:2]\n",
    "        new_rows, new_cols = int(rows/resizeFactor), int(cols/resizeFactor)\n",
    "        # Downsample the image\n",
    "        if (resizeFactor%2 == 1):\n",
    "            F = cv2.GaussianBlur(F, kernel_size, 0)\n",
    "            F = cv2.resize(F, (new_cols, new_rows), cv2.INTER_AREA)\n",
    "        else:\n",
    "            F = cv2.pyrDown(F)\n",
    "        gpB.append(F)\n",
    "    # pyramid updated length and widths\n",
    "    width = width/pow(resizeFactor, level)\n",
    "    height = height/pow(resizeFactor, level)\n",
    "    # pyramid point positon\n",
    "    ix = ix/pow(resizeFactor, level)\n",
    "    iy = iy/pow(resizeFactor,level)\n",
    "    #pyramid for loop\n",
    "    for i in range(level, -1, -1):\n",
    "        # final vector to be added to global point p\n",
    "        subU = 0\n",
    "        subV = 0\n",
    "        Inew = gpA[i].astype(np.float)\n",
    "        Iold = gpB[i].astype(np.float)\n",
    "        # difference image  \n",
    "        dIm = np.array(Inew) - np.array(Iold)\n",
    "        dIm[np.absolute(dIm)<10 ] = 0\n",
    "        [dVm, dUm] = np.gradient(Iold)\n",
    "        #row, column -> y, x\n",
    "        intX = int(ix)\n",
    "        intY = int(iy)\n",
    "        Intwidth = int(width)\n",
    "        IntHeight = int(height)\n",
    "        # specified blob\n",
    "        dI = dIm[intY:intY+IntHeight, intX:intX+Intwidth]\n",
    "        dU = dUm[intY:intY+IntHeight, intX:intX+Intwidth]\n",
    "        dV = dVm[intY:intY+IntHeight, intX:intX+Intwidth]\n",
    "        # vector, flatten matrix\n",
    "        dIv = dI.flatten()\n",
    "        dUv = dU.flatten()\n",
    "        dVv = dV.flatten()\n",
    "        dIv = np.array([dIv])\n",
    "        #least squares\n",
    "        M = np.array([dUv, dVv])\n",
    "        dIv = dIv.T\n",
    "        M = M.T\n",
    "        arr = np.linalg.lstsq(M,dIv, rcond=None)[0]\n",
    "        u, v = -arr \n",
    "        \n",
    "        subU = subU +  u*pow(resizeFactor, i)\n",
    "        #y motion\n",
    "        subV = subV +  v*(pow(resizeFactor,i))\n",
    "        Iold = Iold.astype(np.uint8)\n",
    "        # print(subU, subV)\n",
    "        cv2.rectangle(Iold, (intX, intY),(intX + Intwidth, intY + IntHeight),(0, 255, 255),4)\n",
    "        # while True:\n",
    "        #     # dIm[dIm>=80] = 255\n",
    "        #     cv2.imshow(\"test\", Iold)\n",
    "        #     k = cv2.waitKey(1)\n",
    "        #     if k%256 == 27:\n",
    "        #         break\n",
    "        # cv2.destroyAllWindows\n",
    "        if (i == 0):\n",
    "            Iold = cv2.imread(path + \"opencv_frame_{}.png\".format(index+1))\n",
    "            cv2.rectangle(Iold, (intX, intY),(intX + Intwidth, intY + IntHeight),(0, 255, 255),4)\n",
    "            # write\n",
    "            result.write(Iold)\n",
    "            ix = ix + subU\n",
    "            iy = iy + subV\n",
    "        else:\n",
    "            #update the local pyramid variables\n",
    "            ix = ix*resizeFactor\n",
    "            iy = iy*resizeFactor\n",
    "            width = width*resizeFactor\n",
    "            height = height*resizeFactor\n",
    "\n",
    "    \n",
    "print(\"finished\")\n",
    "result.release()\n",
    "cv2.destroyAllWindows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a8dfe095fce2b5e88c64a2c3ee084c8e0e0d70b23e7b95b1cfb538be294c5c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
